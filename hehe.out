2018-10-13 05:36:45.827269: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-10-13 05:40:49.756283: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
cpu
{'type_of_interaction': Linear(in_features=100, out_features=3, bias=True), 'eudist_margin': Linear(in_features=100, out_features=4, bias=True), 'dim_of_latent_factor': Linear(in_features=100, out_features=6, bias=True), 'mlp_dim2': Linear(in_features=100, out_features=6, bias=True), 'mlp_dim3': Linear(in_features=100, out_features=6, bias=True), 'mlp_dim1': Linear(in_features=100, out_features=6, bias=True), 'l2_reg': Linear(in_features=100, out_features=5, bias=True)}
('input:', (1, 1, 100))
('hidden:', (1, 1, 100))
('dim_of_latent_factor', [25, 50, 75, 100, 125, 150])
('output:', (1, 100))
('softmax_outputs_stored:', [tensor([[0.1834, 0.1479, 0.1626, 0.1687, 0.1586, 0.1787]], grad_fn=<SoftmaxBackward>)])
('input:', (1, 100))
('hidden:', (1, 1, 100))
('l2_reg', [0.1, 0.01, 0.001, 0.0001, 1e-05])
('output:', (1, 100))
('softmax_outputs_stored:', [tensor([[0.1834, 0.1479, 0.1626, 0.1687, 0.1586, 0.1787]], grad_fn=<SoftmaxBackward>), tensor([[0.2159, 0.1748, 0.1897, 0.2132, 0.2065]], grad_fn=<SoftmaxBackward>)])
('input:', (1, 100))
('hidden:', (1, 1, 100))
('type_of_interaction', ['PairwiseEuDist', 'PairwiseLog', 'PointwiseMLPCE'])
('output:', (1, 100))
('softmax_outputs_stored:', [tensor([[0.1834, 0.1479, 0.1626, 0.1687, 0.1586, 0.1787]], grad_fn=<SoftmaxBackward>), tensor([[0.2159, 0.1748, 0.1897, 0.2132, 0.2065]], grad_fn=<SoftmaxBackward>), tensor([[0.3030, 0.3276, 0.3694]], grad_fn=<SoftmaxBackward>)])
('input:', (1, 100))
('hidden:', (1, 1, 100))
4
('softmax_outputs: ', tensor([[0.1834, 0.1479, 0.1626, 0.1687, 0.1586, 0.1787]], grad_fn=<SoftmaxBackward>))
('softmax_outputs: ', tensor([[0.2159, 0.1748, 0.1897, 0.2132, 0.2065]], grad_fn=<SoftmaxBackward>))
('softmax_outputs: ', tensor([[0.3030, 0.3276, 0.3694]], grad_fn=<SoftmaxBackward>))
('softmax_outputs: ', tensor([[0.2498, 0.2449, 0.2714, 0.2339]], grad_fn=<SoftmaxBackward>))
resulted_str:
3_0_0_3
reward: 0.0956796792791
('loss:', tensor(0.5702, grad_fn=<NegBackward>))
('input:', (1, 1, 100))
('hidden:', (1, 1, 100))
('dim_of_latent_factor', [25, 50, 75, 100, 125, 150])
('output:', (1, 100))
('softmax_outputs_stored:', [tensor([[0.1824, 0.1503, 0.1605, 0.1748, 0.1601, 0.1720]], grad_fn=<SoftmaxBackward>)])
('input:', (1, 100))
('hidden:', (1, 1, 100))
('l2_reg', [0.1, 0.01, 0.001, 0.0001, 1e-05])
('output:', (1, 100))
('softmax_outputs_stored:', [tensor([[0.1824, 0.1503, 0.1605, 0.1748, 0.1601, 0.1720]], grad_fn=<SoftmaxBackward>), tensor([[0.2608, 0.1552, 0.1725, 0.2077, 0.2038]], grad_fn=<SoftmaxBackward>)])
('input:', (1, 100))
('hidden:', (1, 1, 100))
('type_of_interaction', ['PairwiseEuDist', 'PairwiseLog', 'PointwiseMLPCE'])
('output:', (1, 100))
('softmax_outputs_stored:', [tensor([[0.1824, 0.1503, 0.1605, 0.1748, 0.1601, 0.1720]], grad_fn=<SoftmaxBackward>), tensor([[0.2608, 0.1552, 0.1725, 0.2077, 0.2038]], grad_fn=<SoftmaxBackward>), tensor([[0.3841, 0.2732, 0.3427]], grad_fn=<SoftmaxBackward>)])
('input:', (1, 100))
('hidden:', (1, 1, 100))
('input:', (1, 100))
('hidden:', (1, 1, 100))
('input:', (1, 100))
('hidden:', (1, 1, 100))
6
('softmax_outputs: ', tensor([[0.1824, 0.1503, 0.1605, 0.1748, 0.1601, 0.1720]], grad_fn=<SoftmaxBackward>))
('softmax_outputs: ', tensor([[0.2608, 0.1552, 0.1725, 0.2077, 0.2038]], grad_fn=<SoftmaxBackward>))
('softmax_outputs: ', tensor([[0.3841, 0.2732, 0.3427]], grad_fn=<SoftmaxBackward>))
('softmax_outputs: ', tensor([[0.1754, 0.1489, 0.1825, 0.1644, 0.1702, 0.1586]], grad_fn=<SoftmaxBackward>))
('softmax_outputs: ', tensor([[0.1709, 0.1458, 0.1638, 0.1653, 0.1724, 0.1818]], grad_fn=<SoftmaxBackward>))
('softmax_outputs: ', tensor([[0.1679, 0.1981, 0.1549, 0.1342, 0.1627, 0.1822]], grad_fn=<SoftmaxBackward>))
resulted_str:
1_0_2_1_4_5
reward: -0.120371782185
('loss:', tensor(-1.1646, grad_fn=<NegBackward>))
('input:', (1, 1, 100))
('hidden:', (1, 1, 100))
('dim_of_latent_factor', [25, 50, 75, 100, 125, 150])
('output:', (1, 100))
('softmax_outputs_stored:', [tensor([[0.1850, 0.1435, 0.1624, 0.1818, 0.1579, 0.1694]], grad_fn=<SoftmaxBackward>)])
('input:', (1, 100))
('hidden:', (1, 1, 100))
('l2_reg', [0.1, 0.01, 0